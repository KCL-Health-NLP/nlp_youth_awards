{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting word context vectors\n",
        "*Written by Tao Wang and Angus Roberts, August 2024*\n",
        "\n",
        "Words keep familiar friends. The famous linguist J.R. Firth said:\n",
        "\n",
        "> *You shall know a word by the company it keeps*\n",
        "\n",
        "We find that the word *apple* often appears near the words *eat* and *pie*. So does the word *strawberry*. The word *dog*, on the other hand, has different friends, like *tail* and *bark*.\n",
        "\n",
        "More specifically, groups of words are used in very particular ways. For example, some verbs are only used with certain subjects (people talk, but rocks don't talk much), and certain adjectives will only apply to certain groups of nouns (you might use an adjective to describe the taste of a food, but not the taste of a vehicle).\n",
        "\n",
        "We will examine this idea using the [iWeb corpus](https://www.english-corpora.org/iweb/): a corpus of 14 billion words in 22 million systematically selected English language web pages. This can be searched and analysed using the tools at [English-Corpora.org](https://www.english-corpora.org/). We have used these tools to look at a few words, and to find what other words appear in their context (on the same web page). We have saved these in a spreadsheet, and will load this in to Python to take a look.\n"
      ],
      "metadata": {
        "id": "0_UEn-eIqh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set everything up\n",
        "\n",
        "First we need to load some Python libraries - modules of pre-written code that have functionality we can use. We will use:\n",
        "\n",
        "- Pandas which contains code to load and manipulate data - we will call this **pd**;\n",
        "- pyplot which contains code to plot graphs - we will call this **plt**"
      ],
      "metadata": {
        "id": "zpcInBTXuZox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some libraries that we need.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OdP3mSNWknK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will fetch our spreadsheet of words and their context, by copying the whole github repository where it lives, in to the Colab filespace. We can read the spreadsheet from Python, using Pandas *read_excel* method. This will read each sheet, storing them in separate Pandas *dataframes*. We will put them all in a variable called *contexts*. This is a Python Dictionary - it contains a set of keys (the names of our sheets), each of which has a value (the dataframe holding the data for that sheet)."
      ],
      "metadata": {
        "id": "pM9WNu-zxQ81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy files from github in to the local Colab filespace.\n",
        "!git clone --quiet https://github.com/KCL-Health-NLP/nlp_youth_awards.git\n",
        "print(\"Done copying files\")"
      ],
      "metadata": {
        "id": "R_ACHkTec88S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the spreadsheet.\n",
        "contexts = pd.read_excel('./nlp_youth_awards/contexts.xlsx', sheet_name=None)"
      ],
      "metadata": {
        "id": "0faPUfXkel3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at what we have read in. First, we will print out the keys - i.e. the names of the dataframes stored in the *contexts* variable. These are the words for which the spreadsheet contains contexts."
      ],
      "metadata": {
        "id": "ykb1UgFYyTps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the names of the sheets that have been read in.\n",
        "# These are our words.\n",
        "print(contexts.keys())"
      ],
      "metadata": {
        "id": "YdjXhuijfBnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at the dataframe for one of our words. We will list just the first 10 rows. See how it contains columns and rows read directly from the spreadsheet. Each row gives one context word found in the context of the sheet word, and the count for the number of times this has been found with the sheet word. The top 50 commonest context words are given."
      ],
      "metadata": {
        "id": "sTK_Zo8-zGh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the first few lines of one of the sheets.\n",
        "# You can change this to look at others.\n",
        "print(contexts['lettuce'].head(10))"
      ],
      "metadata": {
        "id": "c3mbO_rRkwHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A function to look up context word dimensions\n",
        "We can imagine each of our context words being a dimension in some space. Imagine a 2 dimension space for now, like a 2D graph with an x and y axis. For any given word we can plot a vector that shows how often our word is found with occurs in the same web pages as these context words, i.e. the size of these two dimensions. So, if we are considering the word *apple*, and the word *eat* is found in 100 web pages that mention *apple*, whereas the word *tree* is found in 80 pages, we might plot the (eat, tree) dimensions of *apple* as the vector:\n",
        "\n",
        "`(100, 80)`\n",
        "\n",
        "Other words will have different vectors in the same 2 dimension space.\n",
        "\n",
        "To model this in our code, we need a function that will look up a dimension in a word dataframe. We can then use this in our code wherever we need the a dimension for a word.\n",
        "\n"
      ],
      "metadata": {
        "id": "pH0KMqJXuP8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes a word, and a dimension word.\n",
        "# It looks up the number of times the dimension word\n",
        "# occurs with the word. The value of the dimension\n",
        "# is returned. If the dimension word is not found,\n",
        "# zero is returned\n",
        "def get_dimension_value(word, dimension):\n",
        "\n",
        "  # Get the dataframe of dimensions for this word\n",
        "  word_context = contexts[word]\n",
        "\n",
        "  # If the dimension word is in the context column of the table\n",
        "  if dimension in word_context['context'].values:\n",
        "\n",
        "    # The value of the dimension is found in the row named for that dimension\n",
        "    # and in the relative-count column\n",
        "    value = word_context.loc[word_context['context'] == dimension, ['relative-count']].values[0][0]\n",
        "\n",
        "  # If the dimension word is not found in the table\n",
        "  else:\n",
        "    value = 0\n",
        "\n",
        "  return value"
      ],
      "metadata": {
        "id": "xQo_Np6LUS4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make the vectors\n",
        "\n",
        "Now that we can look up the sizes of different dimensions for words, let's make some vectors! We will choose some words to vectorise, and a couple of dimensions against which to vectorise them. We've put some ideas for this below. You should change the words, and the dimensions, to see what happens."
      ],
      "metadata": {
        "id": "qAQDYbAArEjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose some words for which we will create vectors\n",
        "words_to_vectorise = ['lettuce', 'cucumber', 'butter', 'sugar']\n",
        "\n",
        "# Choose vector dimensions\n",
        "x_dimension = 'bowl'\n",
        "y_dimension = 'salad'"
      ],
      "metadata": {
        "id": "INxPxCu_vTfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now vectorise our words, against the two dimensions. Once we have done this, we will print out the vectors and take a look."
      ],
      "metadata": {
        "id": "ZtLmdc8A2aVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make an empty list to hold the vectors\n",
        "vectors = []\n",
        "\n",
        "# Go through the words one at a time\n",
        "for word in words_to_vectorise:\n",
        "\n",
        "  # Look up the values of the two dimensions\n",
        "  x_value = get_dimension_value(word, x_dimension)\n",
        "  y_value = get_dimension_value(word, y_dimension)\n",
        "\n",
        "  # Add the dimensions in to the vectors\n",
        "  v = [word, (x_value, y_value)]\n",
        "  print(v)\n",
        "  vectors.append(v)\n",
        "\n",
        "# Take a look at the vectors\n",
        "print(vectors)\n",
        "\n"
      ],
      "metadata": {
        "id": "qX_PBj5LmFcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the vectors\n",
        "\n",
        "Now we have some vectors, what can we do with them? An obvious thing to do is plot them - let's do that first."
      ],
      "metadata": {
        "id": "F6FFGNt0rH3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Go through the vectors and get our the word\n",
        "# and the vectors, and plot each one\n",
        "for word, vec in vectors:\n",
        "\n",
        "    # get our x and y dimensions\n",
        "    x = vec[0]\n",
        "    y = vec[1]\n",
        "\n",
        "    # Plot an arrow\n",
        "    plt.quiver(0, 0, x, y, angles='xy', scale_units='xy', scale=1)\n",
        "\n",
        "    # Add a label at the end of each arrow\n",
        "    plt.text(x+2, y+2, word, fontsize=8)\n",
        "\n",
        "# Set axis labels and limits\n",
        "plt.xlabel(x_dimension)\n",
        "plt.ylabel(y_dimension)\n",
        "plt.xlim((-1, 101))\n",
        "plt.ylim((-1, 101))\n",
        "\n",
        "# Show the graph\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YZOyESNeroRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next steps\n",
        "- Try changing the words and dimensions, to explore our small vocabulary\n",
        "- What else might we do with vectors?\n",
        "- What about adding more dimensions? How about 3, or 4? How about more?\n",
        "- How might we use these vectors?"
      ],
      "metadata": {
        "id": "-yoZp_685HXa"
      }
    }
  ]
}